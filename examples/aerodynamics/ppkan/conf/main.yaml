hydra:
  run:
    # dynamic output directory according to running time and override name
    dir: outputs-${model}/${now:%Y-%m-%d}/${now:%H-%M-%S}/
  job:
    name: ${mode} # name of logfile
    chdir: false # keep current working direcotry unchanged
  sweep:
    # output directory for multirun
    dir: ${hydra.run.dir}
    subdir: ./

# Setting
mode: "train"
seed: 0
output_dir: ${hydra:run.dir}
device: gpu
dtype: float32

# DataSet
DATA:
  path: "./Dataset"
  task: "full"
  download: False
  sample_points: 10000
  batch_size: 2000
  shuffle: True
  boundary_line_ratio: 0.2
  




# Model
model: "DeepONet" # "KANONet"
MLPMODEL:
  branch1_in: 63
  branch1_hidden: [512, 256, 256, 128, 128]
  trunk_in: 2
  trunk_hidden: [128, 256, 256, 128, 128]
KANMODEL:
  width_branch1: [63, 128, 128, 64]
  grid_range_b1: [-3.0, 3.0]
  grid_size_b1: 50

  width_trunk: [2, 128, 128, 64]
  grid_range_t: [-1.5, 4.0]
  grid_size_t: 50
  

# Hyper-parameters
# train
epochs: 500
lr: 0.001
save_freq: 10
enable_ddp: false
resume_ep: -1
checkpoint: null

# eval
pred_ckpt: null
