# PP-FNO: A surrogate model for super-large 3D CFD simulations

## Data format

PP-FNO is a data-driven model, where the data is generated by CFD (at present CFD with RANS model). PP-FNO learns to map geometry (CFD computation domain) to cell information (CFD results, such as pressure, wall-shear stress, etc). 
- The training data of PP-FNO is extracted from CFD result files:
  - Original CFD files
```
Star CCM+: case.csv (CFD results) + case.stl (Geometry) + case.json (cfd params)
```

  - Transformed dataset (2 cases)

```
dataset/
    - 0001_case001 (empty dir)
    - 0002_case002 (empty dir)
    - area_0001.npy
    - area_0002.npy
    - centroid_0001.npy
    - centroid_0002.npy
    - df_0001.npy
    - df_0002.npy
    - info_0001.npy
    - info_0002.npy
    - normal_0001.npy
    - normal_0002.npy
    - pressure_0001.npy
    - pressure_0002.npy
    - wallshearstress_0001.npy
    - wallshearstress_0002.npy
    - area_bounds.txt
    - global_bounds.txt
    - info_bounds.txt
    - train_pressure_mean_std.txt
    - train_wallshearstress_mean_std.txt

```

> 

## How to run

    # Training dataset preprocess: .csv+.stl+.json -> .npy + .pdparams + .txt
    python trainDataPreprocess.py pre_input_path=/train_dataset pre_output_path=/train_dataset_processed process_mode=train

    # Inference dataset preprocess: .stl+.json -> .npy + .pdparams
    python inferenceDataPreprocess.py pre_input_path=/inference_dataset pre_output_path=/inference_dataset_processed bounds_dir=/train_dataset_processed process_mode=infer

    # Parallel training
    python -m paddle.distributed.launch --gpus=0,1 train.py train_input_path=/train_dataset_processed train_ratio=0.7 test_ratio=0.3 save_per_epoch=200 train_output_path=/train_output num_epochs=1000 finetuning_epochs=51

    # Offline inference
    python -m paddle.distributed.launch --gpus=0 inference.py reason_input_path=/inference_dataset_processed reason_output_path=/inference_output save_eval_results=false state=/checkpoints/GNOFNOGNO_all.pdparams pre_output_path=/train_dataset_processed

    # Start online inference service
    python -m paddle.distributed.launch --gpus=0 inference_server.py pd_path=/checkpoints/GNOFNOGNO_all.pdparams

    # Online inference
    curl -X POST "http://0.0.0.0:8087/api/v1/inference" -H "Content-Type: application/json" -d '{"reason_output_path":"/inference_output", "reason_input_path":"/inference_dataset_processed", "pre_output_path":"/train_dataset_processed"}'

